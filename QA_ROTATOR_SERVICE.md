# ğŸ”¬ NCLEX-RN NGN 2026 â€” AI Quality Assurance Rotator Service

> **Codename: SENTINEL**
> *14-Key Multi-Role Deep Audit Engine for World-Class Item Bank Integrity*

---

## ğŸ¯ Mission Statement

This service deploys **14 AI agents** â€” each with a distinct **clinical psychometrician role** â€” in a rotating pipeline against the **live Supabase-hosted item vault**. Every item is subjected to a **7-pass deep audit** that catches what no single-pass check can: logic inconsistencies, scoring model violations, generic rationale filler, missing Study Companion data, and clinical inaccuracies that would disqualify an item from a real NCLEX exam.

---

## âš¡ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SENTINEL ENGINE                       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  KEY  1  â”‚   â”‚  KEY  2  â”‚   â”‚  KEY  3  â”‚  ...Ã—14    â”‚
â”‚  â”‚ ROLE: A  â”‚   â”‚ ROLE: B  â”‚   â”‚ ROLE: C  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚              â”‚              â”‚                   â”‚
â”‚       â–¼              â–¼              â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚         ITEM QUEUE (from Supabase)       â”‚           â”‚
â”‚  â”‚  fetch â†’ audit â†’ verdict â†’ heal â†’ push  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚       â”‚                                                 â”‚
â”‚       â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚       SENTINEL REPORT (JSON + Console)   â”‚           â”‚
â”‚  â”‚   per-item verdicts, auto-healed count,  â”‚           â”‚
â”‚  â”‚   quarantined items, compliance score    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Execution Mode**: Sequential items, parallel passes per item.
**Speed Target**: ~500 items audited in < 90 minutes using 14 keys at 4s pacing.

---

## ğŸ§¬ The 14 Specialist Roles (Key â†’ Role Mapping)

Each of the 14 API keys is assigned a **permanent clinical psychometrician persona**. When an item enters the audit pipeline, the relevant roles are invoked based on the item type. This prevents "generic AI" answers and forces domain-expert depth.

| Key # | Role Codename | Specialist Title | Primary Audit Domain |
|:---:|:---|:---|:---|
| 1 | **STRUCT-VALIDATOR** | Schema & Structure Analyst | JSON schema, required fields, TypeScript interface compliance |
| 2 | **STEM-SURGEON** | Question Stem Psychometrician | Stem clarity, word count (â‰¤50), single-construct focus, no window dressing |
| 3 | **OPTION-ARCHITECT** | Answer Option Strategist | Option count, word count (â‰¤25/opt), distractor plausibility, no "All of the above" |
| 4 | **SCORE-AUDITOR** | Scoring Model Compliance Officer | Correct scoring method per type, maxPoints validation, penalty model accuracy |
| 5 | **RATIONALE-PATHOLOGIST** | Deep Rationale & Pathophysiology Reviewer | No generic filler, pathophysiology depth, incorrect rationale specificity |
| 6 | **PEARL-TRAP-MNEMONIC** | Study Companion Completeness Inspector | clinicalPearls presence & depth, questionTrap actionability, mnemonic accuracy |
| 7 | **SBAR-COMPLIANCE** | Clinical Documentation Specialist | SBAR format, 120â€“160 word count, military time, terminology synchronization |
| 8 | **EHR-SYNC** | Clinical Data Synchronization Auditor | Tab exhaustion, lab/vital/med sync with stem, no orphaned references |
| 9 | **PEDAGOGY-MAPPER** | Educational Taxonomy Validator | Bloom level accuracy, CJMM step alignment, NCLEX category correctness, difficulty calibration |
| 10 | **ITEM-TYPE-LOGIC** | NGN Type-Specific Logic Enforcer | Type-specific rule enforcement (highlight spans, matrix rows, bowtie wings, trend dataPoints) |
| 11 | **CLINICAL-ACCURACY** | Board-Certified Clinical Content Expert | Medical/nursing accuracy, drug dosages, lab reference ranges, pathophysiology correctness |
| 12 | **EQUITY-ETHICS** | Health Equity & Unbiased Care Reviewer | SDOH integration, inclusive language, cultural competency, digital privacy compliance |
| 13 | **ANSWER-BREAKDOWN** | Evidence Table & Breakdown Auditor | answerBreakdown completeness, per-option rationale, correct/incorrect labeling accuracy |
| 14 | **HEALER** | Auto-Repair & Remediation Agent | Takes all flagged defects and generates a corrected version of the item |

---

## ğŸ” The 7-Pass Deep Audit Pipeline

Every item goes through **7 sequential audit passes**. Each pass uses a **different key/role combination** to prevent blind spots.

### Pass 1: Structural Integrity (Keys 1 + 4)
> **STRUCT-VALIDATOR** + **SCORE-AUDITOR**

**Checks (deterministic â€” no AI needed):**
```
â–¡ item.id exists and follows naming convention
â–¡ item.type is one of the 14 valid NGN types
â–¡ item.stem exists and is non-empty
â–¡ item.pedagogy exists with all 5 required fields:
    â–¡ bloomLevel âˆˆ {remember, understand, apply, analyze, evaluate, create}
    â–¡ cjmmStep âˆˆ {recognizeCues, analyzeCues, prioritizeHypotheses, generateSolutions, takeAction, evaluateOutcomes}
    â–¡ nclexCategory âˆˆ {8 valid categories}
    â–¡ difficulty âˆˆ {1, 2, 3, 4, 5}
    â–¡ topicTags is array with length â‰¥ 1
â–¡ item.rationale exists with:
    â–¡ rationale.correct is string, length â‰¥ 80 chars
    â–¡ rationale.incorrect is string or array, length â‰¥ 80 chars
    â–¡ rationale.reviewUnits is array with length â‰¥ 1
    â–¡ rationale.clinicalPearls is array with length â‰¥ 1
    â–¡ rationale.questionTrap exists with {trap, howToOvercome}
    â–¡ rationale.mnemonic exists with {title, expansion}
    â–¡ rationale.answerBreakdown is array with length â‰¥ 1
â–¡ item.scoring exists with:
    â–¡ scoring.method âˆˆ {dichotomous, polytomous, linkage}
    â–¡ scoring.maxPoints is number â‰¥ 1
â–¡ SCORING MODEL matches item type:
    â–¡ multipleChoice/trend/priorityAction/graphic/audioVideo/chartExhibit â†’ dichotomous, maxPoints: 1
    â–¡ highlight/selectAll â†’ polytomous, +/- 1.0 penalty
    â–¡ selectN â†’ polytomous, 0/1 no penalty
    â–¡ matrixMatch â†’ polytomous, 0/1 per row
    â–¡ clozeDropdown/dragAndDropCloze â†’ polytomous, 0/1 per blank
    â–¡ bowtie â†’ linkage
    â–¡ orderedResponse â†’ dichotomous
```

**Verdict**: `PASS` | `FAIL` with list of missing/invalid fields.

---

### Pass 2: Stem & Option Quality (Keys 2 + 3)
> **STEM-SURGEON** + **OPTION-ARCHITECT**

**AI Prompt (Key 2):**
```
You are an NCLEX-RN 2026 Question Stem Psychometrician.

Analyze this item stem for compliance with NCSBN 2026 standards:
- Is the stem â‰¤ 50 words? (Count exactly)
- Does it focus on ONE clinical judgment construct?
- Is there any "window dressing" (irrelevant information)?
- Does it use clear, direct language appropriate for a licensing exam?
- Is the clinical scenario clinically accurate?

ITEM: {item JSON}

Return JSON: {
  "wordCount": number,
  "singleConstruct": boolean,
  "windowDressing": string[] | null,
  "clarity": "excellent" | "acceptable" | "poor",
  "issues": string[]
}
```

**AI Prompt (Key 3):**
```
You are an NCLEX-RN 2026 Answer Option Strategist.

Audit the answer options of this NGN item:
- Correct option count per type? (MC=4, SATA=5-10, SelectN=5-8, etc.)
- Each option â‰¤ 25 words?
- Are distractors clinically plausible (not obviously wrong)?
- Any "All of the above" / "None of the above" violations?
- Is the correct answer defensible with evidence-based nursing practice?
- Are options mutually exclusive where required?
- Is option ordering randomized (no pattern like "longest is correct")?

ITEM: {item JSON}

Return JSON: {
  "optionCount": number,
  "expectedCount": number,
  "maxOptionWordCount": number,
  "plausibilityScore": 1-10,
  "issues": string[]
}
```

---

### Pass 3: Rationale Depth & Anti-Filler (Key 5)
> **RATIONALE-PATHOLOGIST**

**AI Prompt:**
```
You are a Board-Certified Critical Care Nurse Educator reviewing rationale quality.

ZERO TOLERANCE for generic rationale. Analyze this item's rationale:

1. CORRECT RATIONALE: Does it explain the pathophysiology or safety/legal basis? 
   Or does it just restate the answer? (e.g., "This is correct because it is the right answer" = FAIL)
2. INCORRECT RATIONALE: Does each distractor get a SPECIFIC explanation of why it's wrong 
   in THIS clinical context? Or is it generic? (e.g., "This is not the priority" without explaining WHY = FAIL)
3. CLINICAL PEARLS: Are they actionable nursing insights? Or generic textbook summaries?
   (e.g., "Monitor vitals" = FAIL. "In DKA, potassium shifts intracellularly as pH normalizes â€” 
   monitor K+ q2h even if initially hyperkalemic" = PASS)
4. QUESTION TRAP: Does it identify a specific, realistic test-taking error? 
   Does "howToOvercome" give a concrete strategy?
5. MNEMONIC: Is it relevant to the topic? Is the expansion accurate?
6. ANSWER BREAKDOWN: Does every option have a labeled breakdown entry?

ITEM: {item JSON}

Return JSON: {
  "correctRationaleDepth": "pathophysiological" | "surface" | "generic",
  "incorrectRationaleDepth": "specific" | "semi-specific" | "generic",
  "pearlQuality": "actionable" | "textbook" | "missing",
  "trapQuality": "specific" | "vague" | "missing",
  "mnemonicAccuracy": "accurate" | "inaccurate" | "missing",
  "breakdownComplete": boolean,
  "overallGrade": "A" | "B" | "C" | "D" | "F",
  "issues": string[],
  "suggestedFixes": string[]
}
```

---

### Pass 4: Study Companion & Instructional Completeness (Key 6)
> **PEARL-TRAP-MNEMONIC**

**AI Prompt:**
```
You are the Study Companion QA Lead for the NCLEX-RN 2026 Simulator.

The Study Companion sidebar aggregates clinicalPearls, questionTraps, and mnemonics 
from answered items. If ANY of these are missing or low-quality, the student gets 
an empty or useless study notebook.

Audit this item for Study Companion readiness:

1. clinicalPearls: Array of â‰¥1 entries. Each entry must be:
   - Specific to this clinical scenario (not generic nursing advice)
   - Actionable (tells the nurse WHAT to do or WHY)
   - â‰¥ 30 characters each
   
2. questionTrap: Object with {trap, howToOvercome}. Must be:
   - trap: Names the specific cognitive error students make (â‰¥ 20 chars)
   - howToOvercome: Provides concrete strategy (â‰¥ 30 chars)
   
3. mnemonic: Object with {title, expansion}. Must be:
   - title: A real, recognized mnemonic (e.g., "MONA", "SBAR", "FAST")
   - expansion: Accurate letter-by-letter expansion
   
4. reviewUnits: Array of â‰¥1 entries. Each entry must have:
   - heading: Topic title
   - body: Educational content (â‰¥ 50 chars)
   - source: Citation or textbook reference
   
5. answerBreakdown: Array matching option count. Each entry must have:
   - label: Option identifier (A, B, C, etc.)
   - content: Explanation (â‰¥ 30 chars)
   - isCorrect: boolean

ITEM: {item JSON}

Return JSON: {
  "pearlsPresent": boolean,
  "pearlsCount": number,
  "pearlsActionable": boolean,
  "trapPresent": boolean,
  "trapSpecific": boolean,
  "mnemonicPresent": boolean,
  "mnemonicAccurate": boolean,
  "reviewUnitsPresent": boolean,
  "breakdownComplete": boolean,
  "companionReadiness": "ready" | "partial" | "empty",
  "issues": string[]
}
```

---

### Pass 5: Clinical Accuracy & EHR Synchronization (Keys 8 + 11)
> **EHR-SYNC** + **CLINICAL-ACCURACY**

**AI Prompt (Key 11):**
```
You are a Board-Certified Advanced Practice Nurse reviewing clinical accuracy.

Verify this NCLEX item for medical/nursing accuracy:
1. Are drug dosages within safe therapeutic ranges?
2. Are lab reference ranges correct per standard US adult values?
3. Is the pathophysiology description accurate?
4. Are nursing interventions evidence-based and within RN scope?
5. Are vital sign values physiologically consistent with the diagnosis?
6. Is the correct answer truly the BEST answer per current evidence-based practice?

ITEM: {item JSON}

Return JSON: {
  "clinicallyAccurate": boolean,
  "drugSafety": "safe" | "borderline" | "unsafe" | "n/a",
  "labAccuracy": "accurate" | "inaccurate" | "n/a",
  "pathophysiology": "accurate" | "partially" | "inaccurate",
  "interventionScope": "within_RN" | "outside_RN" | "n/a",
  "bestAnswer": "defensible" | "arguable" | "incorrect",
  "issues": string[]
}
```

**AI Prompt (Key 8):**
```
You are an EHR Clinical Data Synchronization Auditor.

Check if the item's clinical context (itemContext/tabs) is synchronized with the stem:
1. If stem mentions a lab value â†’ is it in the Labs tab with correct value?
2. If stem mentions a medication â†’ is it in the MAR tab?
3. If stem mentions vitals â†’ are they in the Vitals tab?
4. If stem references imaging â†’ is it in the Radiology tab?
5. Are there â‰¥ 3 time-points for trending data?
6. Is the SBAR note 120â€“160 words in SBAR format with military time?

ITEM: {item JSON}

Return JSON: {
  "labSync": "synced" | "missing" | "n/a",
  "medSync": "synced" | "missing" | "n/a",
  "vitalSync": "synced" | "missing" | "n/a",
  "imagingSync": "synced" | "missing" | "n/a",
  "trendingPoints": number,
  "sbarWordCount": number,
  "sbarFormat": boolean,
  "militaryTime": boolean,
  "issues": string[]
}
```

---

### Pass 6: Item-Type-Specific Logic (Key 10)
> **ITEM-TYPE-LOGIC**

**Rules Engine (deterministic + AI):**

| Item Type | Specific Checks |
|:---|:---|
| `highlight` | â‰¥6 spans, â‰¥2 distractors, `correctSpanIndices` array valid, `passage` exists |
| `multipleChoice` | Exactly 4 options, `correctOptionId` matches an option id |
| `selectAll` | 5â€“10 options, `correctOptionIds` array with â‰¥2 entries |
| `selectN` | 5â€“8 options, stem contains "Select [N]", `requiredCount` matches N |
| `orderedResponse` | `correctOrder` array matches `options` ids, all options used once |
| `matrixMatch` | 3â€“5 rows, `columns` array, `correctMatches` object covers all rows |
| `clozeDropdown` | 1â€“3 `blanks`, each blank has `options` array and `correctOption` |
| `dragAndDropCloze` | `template` with blanks, `options` array, `blanks` with `correctOption` |
| `bowtie` | `actions` (â‰¥4 options), `conditions` (â‰¥3), `parameters` (â‰¥4), `correctActionIds` (2), `correctParameterIds` (2), `condition` string |
| `trend` | `dataPoints` array with â‰¥3 entries OR `itemContext.tabs` fallback, `options` array |
| `priorityAction` | Exactly 4 options, `correctOptionId`, focus on "first action" |
| `hotspot` | `imageUrl` exists, `hotspots` array with coordinates |
| `graphic` | `imageUrl` or graphical context, standard MC structure |
| `audioVideo` | `mediaUrl` exists, standard MC structure |
| `chartExhibit` | `exhibits` or `itemContext.tabs` with â‰¥2 data sources |

---

### Pass 7: Auto-Heal & Remediation (Key 14)
> **HEALER**

Items that fail **any** of Passes 1â€“6 are sent to the HEALER for automatic repair.

**AI Prompt:**
```
You are the NCLEX-RN 2026 Item Remediation Specialist.

This item FAILED quality assurance with the following defects:
{defect_list}

Your mission: Fix ALL defects while preserving the clinical intent.

RULES:
1. Do NOT change the correct answer or core clinical scenario
2. ADD missing fields (clinicalPearls, questionTrap, mnemonic, answerBreakdown, reviewUnits)
3. REWRITE generic rationale with pathophysiology-based explanations
4. FIX scoring model if incorrect
5. ENSURE answerBreakdown has one entry per option with {label, content, isCorrect}
6. ENSURE clinicalPearls are actionable, not textbook summaries
7. ENSURE questionTrap names a specific cognitive error
8. ENSURE mnemonic is real and accurately expanded

ORIGINAL ITEM: {item JSON}
DEFECTS: {defect_list}

Return the COMPLETE corrected item as pure JSON.
```

---

## ğŸš€ Execution Workflow

### Quick-Start Command
```bash
node sentinel_qa_rotator.cjs
```

### Step-by-Step Pipeline

```
STEP 1: FETCH
  â””â”€â”€ Pull all items from Supabase cloud vault (paginated, 1000/page)
  â””â”€â”€ Also scan local data/vaultItems.json for any items not yet in cloud
  â””â”€â”€ Deduplicate by item.id â†’ create master audit queue

STEP 2: TRIAGE (No AI â€” Pure Code)
  â””â”€â”€ Run Pass 1 (Structural Integrity) on ALL items
  â””â”€â”€ Classify: PASS â†’ continue | FAIL â†’ flag for healing
  â””â”€â”€ Generate structural compliance report

STEP 3: DEEP AUDIT (AI Passes 2â€“6)
  â””â”€â”€ For each item in queue:
      â”œâ”€â”€ Pass 2: Stem & Options (Keys 2, 3) â€” parallel
      â”œâ”€â”€ Pass 3: Rationale Depth (Key 5)
      â”œâ”€â”€ Pass 4: Study Companion (Key 6)
      â”œâ”€â”€ Pass 5: Clinical + EHR Sync (Keys 8, 11) â€” parallel
      â””â”€â”€ Pass 6: Type-Specific Logic (Key 10)
  â””â”€â”€ Compile per-item verdicts into AuditResult[]

STEP 4: HEAL
  â””â”€â”€ Filter items with severity â‰¥ MEDIUM
  â””â”€â”€ Send to HEALER (Key 14) with defect list
  â””â”€â”€ Validate healed item passes Pass 1 again
  â””â”€â”€ If still failing â†’ QUARANTINE (do not push)

STEP 5: PUSH
  â””â”€â”€ Upsert healed items back to Supabase
  â””â”€â”€ Add "sentinelStatus": "healed_v2026_v{run}" to each item
  â””â”€â”€ Regenerate local vaultItems.json
  â””â”€â”€ Print final SENTINEL REPORT
```

---

## ğŸ“Š SENTINEL Report Format

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  SENTINEL QA REPORT â€” Run #8 â€” 2026-02-24T19:00:00Z
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Total Items Audited:     1,480
  Passed All 7 Checks:    1,203  (81.3%)
  Auto-Healed:              241  (16.3%)
  Quarantined (unfixable):   36  (2.4%)

  â”€â”€ Defect Breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Missing clinicalPearls:           89
  Missing questionTrap:            112
  Missing mnemonic:                 74
  Missing answerBreakdown:         198
  Generic rationale (filler):      143
  Scoring model mismatch:           23
  Stem > 50 words:                  41
  Option count violation:           18
  EHR/Stem desynchronization:       67
  Missing pedagogy fields:          31

  â”€â”€ Type Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  highlight:       120  |  multipleChoice: 280
  selectAll:       150  |  orderedResponse:  60
  matrixMatch:      80  |  clozeDropdown:   110
  dragAndDropCloze:  70  |  bowtie:          90
  trend:            60  |  priorityAction:   80
  hotspot:          40  |  graphic:          50
  audioVideo:       30  |  chartExhibit:     60

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## âš™ï¸ Key Rotation Strategy

```javascript
// 14-Key Rotation with Role Assignment
const KEY_ROLES = {
    1:  'STRUCT-VALIDATOR',
    2:  'STEM-SURGEON',
    3:  'OPTION-ARCHITECT',
    4:  'SCORE-AUDITOR',
    5:  'RATIONALE-PATHOLOGIST',
    6:  'PEARL-TRAP-MNEMONIC',
    7:  'SBAR-COMPLIANCE',
    8:  'EHR-SYNC',
    9:  'PEDAGOGY-MAPPER',
    10: 'ITEM-TYPE-LOGIC',
    11: 'CLINICAL-ACCURACY',
    12: 'EQUITY-ETHICS',
    13: 'ANSWER-BREAKDOWN',
    14: 'HEALER'
};

// Pacing: 4 seconds between API calls to respect rate limits
// Parallelism: 2 concurrent calls max (different keys)
// Retry: 3 attempts with exponential backoff (4s â†’ 8s â†’ 16s)
// Cooldown: 60s pause after 429 (rate limit) errors
```

---

## ğŸ† World-Class Quality Targets

| Metric | Target | Description |
|:---|:---:|:---|
| **Structural Pass Rate** | â‰¥ 99% | All items have required JSON fields |
| **Rationale Depth Score** | â‰¥ A-grade (90%) | No generic filler in any rationale |
| **Study Companion Readiness** | 100% | Every item has Pearls + Trap + Mnemonic |
| **Answer Breakdown Coverage** | 100% | Every option has a labeled breakdown entry |
| **Scoring Model Accuracy** | 100% | Scoring method matches item type per spec |
| **EHR Synchronization** | â‰¥ 95% | Stem references match EHR tab data |
| **Clinical Accuracy** | 100% | Zero medically inaccurate items in production |
| **Equity & Inclusion** | â‰¥ 90% | SDOH/Equity items properly integrated |

---

## ğŸ›¡ï¸ Severity Classification

| Severity | Description | Action |
|:---|:---|:---|
| ğŸ”´ **CRITICAL** | Clinically inaccurate, wrong correct answer, scoring model incorrect | **QUARANTINE** â€” remove from vault |
| ğŸŸ  **HIGH** | Missing rationale, generic filler, no answerBreakdown | **AUTO-HEAL** â€” mandatory repair |
| ğŸŸ¡ **MEDIUM** | Missing pearls/trap/mnemonic, stem > 50 words, option count off | **AUTO-HEAL** â€” best-effort repair |
| ğŸŸ¢ **LOW** | Minor style issues, suboptimal wording, could be improved | **LOG** â€” report only, no action |

---

## ğŸ“ File Structure

```
Senior NCLEX/
â”œâ”€â”€ sentinel_qa_rotator.cjs          â† Main execution script
â”œâ”€â”€ QA_ROTATOR_SERVICE.md            â† This specification (you are here)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sentinel-reports/            â† Historical audit reports
â”‚   â”‚   â”œâ”€â”€ sentinel_run_001.json
â”‚   â”‚   â”œâ”€â”€ sentinel_run_002.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ quarantine/                  â† Items too broken to auto-heal
â”‚       â””â”€â”€ quarantined_items.json
â””â”€â”€ .env                             â† GEMINI_API_KEY_1 through _14
```

---

## ğŸ”„ Recommended Run Schedule

| Frequency | Trigger | Scope |
|:---|:---|:---|
| **After every bulk generation** | Manual | Audit only new items (delta) |
| **Weekly (Sunday 02:00)** | Scheduled | Full vault re-audit |
| **Before any Vercel deploy** | CI/CD hook | Quick structural pass only |
| **On-demand** | `node sentinel_qa_rotator.cjs --item-id=<id>` | Single item deep audit |

---

## ğŸ’¡ Pro Tips for Maximum Speed & Accuracy

1. **Run structural pass first** â€” it's instant (no AI) and catches 40% of defects
2. **Batch AI calls** â€” send 2 items per prompt when doing shallow checks (Pass 2)
3. **Cache verdicts** â€” skip items with `sentinelStatus: healed_v2026_v{latest}` 
4. **Use `responseMimeType: "application/json"`** â€” forces clean JSON output, no markdown pollution
5. **Temperature 0.1** for audit, **0.7** for healing â€” low temp = strict judgment, higher temp = more creative fixes
6. **Log everything** â€” every API call, every verdict, every heal. Forensic trail is non-negotiable
7. **Quarantine > Bad Data** â€” never push a broken item to production. An empty vault slot is better than a wrong one

---

*SENTINEL v1.0 â€” Built for the 2026 NCLEX-RN NGN Standard*
*"No item graduates without a 7-pass audit."*
