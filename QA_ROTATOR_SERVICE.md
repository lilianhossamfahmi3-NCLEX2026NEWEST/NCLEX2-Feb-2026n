# ğŸ”¬ NCLEX-RN NGN 2026 â€” SENTINEL QA Rotator Service v2.0

> **Codename: SENTINEL v2.0**
> *14-Key Multi-Role Deep Audit, Screening, Repair & Enrichment Engine*
> *This system REPLACES all previous QA systems and is the SOLE source of truth for item quality.*

---

## ğŸ¯ Mission Statement

SENTINEL v2.0 is a **one-button** deep audit system accessible from the Vercel-deployed Item Bank.
It uses **14 Gemini API keys** â€” each assigned a permanent clinical psychometrician role â€” to:

1. **SCREEN** every item across 12+ quality dimensions
2. **FIX** all structural, clinical, and content defects automatically
3. **REFILL** missing data with clinically specific, non-generic content
4. **ENRICH** items with isolation logic, allergy cross-referencing, and EHR synchronization
5. **REPORT** a comprehensive quality dashboard with per-item diagnostics and recommendations

**Zero tolerance for generic filler. Zero tolerance for orphaned clinical references.**

---

## âš¡ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VERCEL LIVE DEPLOYMENT                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Item Bank Page â†’ [ğŸ›¡ï¸ Run SENTINEL] â”‚  â† One-Button       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚               â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              SENTINEL v2.0 ENGINE                        â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  PHASE 1: STRUCTURAL PASS (No AI â€” instant)              â”‚ â”‚
â”‚  â”‚    â†’ Schema, fields, scoring model, type rules            â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  PHASE 2: DEEP AI AUDIT (14 Keys Ã— Specialist Roles)     â”‚ â”‚
â”‚  â”‚    â†’ Stem clarity, rationale depth, clinical accuracy     â”‚ â”‚
â”‚  â”‚    â†’ EHR sync, isolation/allergy, Study Companion         â”‚ â”‚
â”‚  â”‚    â†’ SBAR format, option plausibility, pedagogy           â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  PHASE 3: AUTO-HEAL & REFILL                             â”‚ â”‚
â”‚  â”‚    â†’ Replace generic â†’ specific clinical content          â”‚ â”‚
â”‚  â”‚    â†’ Add missing pearls/traps/mnemonics/breakdowns        â”‚ â”‚
â”‚  â”‚    â†’ Sync EHR tabs with question stem                     â”‚ â”‚
â”‚  â”‚    â†’ Set isolation/allergy per clinical context            â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  PHASE 4: PUSH & REPORT                                  â”‚ â”‚
â”‚  â”‚    â†’ Upsert healed items to Supabase                      â”‚ â”‚
â”‚  â”‚    â†’ Generate SENTINEL Report with recommendations        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§¬ The 14 Specialist Roles

| Key | Role | Audit Domain | Specific Focus |
|:---:|:---|:---|:---|
| 1 | **STRUCT-VALIDATOR** | Schema & Structure | JSON fields, TypeScript interface compliance, id naming |
| 2 | **STEM-SURGEON** | Question Stem Quality | â‰¤50 words, single-construct, no window dressing, clarity improvement |
| 3 | **OPTION-ARCHITECT** | Answer Options | Count per type, â‰¤25 words/opt, distractor plausibility, no "All of the above" |
| 4 | **SCORE-AUDITOR** | Scoring Model | Method matches type, maxPoints, penalty model per 2026 spec |
| 5 | **RATIONALE-PATHOLOGIST** | Rationale Depth | No generic filler, pathophysiology basis, per-option explanations |
| 6 | **PEARL-TRAP-MNEMONIC** | Study Companion | clinicalPearls actionability, questionTrap specificity, mnemonic accuracy |
| 7 | **SBAR-COMPLIANCE** | Clinical Documentation | SBAR format, 120â€“160 words, military time, terminology sync with stem |
| 8 | **EHR-SYNC** | Clinical Data Sync | Labs/Vitals/Meds/Imaging in EHR must match stem references |
| 9 | **PEDAGOGY-MAPPER** | Educational Taxonomy | Bloom level, CJMM step, NCLEX category, difficulty calibration |
| 10 | **ITEM-TYPE-LOGIC** | Type-Specific Rules | Highlight spans, matrix rows, bowtie wings, trend dataPoints, etc. |
| 11 | **CLINICAL-ACCURACY** | Medical Correctness | Drug dosages, lab ranges, pathophysiology, intervention scope |
| 12 | **ISOLATION-ALLERGY** | Safety Protocols | Isolation type per diagnosis, allergy cross-ref with MAR meds |
| 13 | **REFILLER** | Data Enrichment | Replace ALL generic content with clinically specific data |
| 14 | **HEALER** | Auto-Repair | Takes all defects and produces a fully corrected item |

---

## ğŸ” The 12 Quality Dimensions

### Dimension 1: Structural Integrity (Key 1 â€” No AI)
```
â–¡ item.id exists and follows naming convention [topic]_[type]_v[version]
â–¡ item.type âˆˆ 14 valid NGN types
â–¡ item.stem exists, non-empty
â–¡ item.pedagogy present with all 5 fields (bloomLevel, cjmmStep, nclexCategory, difficulty, topicTags)
â–¡ item.rationale present with correct/incorrect/reviewUnits/clinicalPearls/questionTrap/mnemonic/answerBreakdown
â–¡ item.scoring present with method + maxPoints
â–¡ Scoring method matches item type per 2026 spec
```

### Dimension 2: Question Stem Quality (Key 2)
```
â–¡ Word count â‰¤ 50
â–¡ Single clinical judgment construct
â–¡ No "window dressing" (irrelevant info)
â–¡ Clear, direct, actionable language
â–¡ If unclear â†’ AI rewrites to be more precise while preserving clinical intent
```

### Dimension 3: Answer Option Logic (Key 3)
```
â–¡ Correct option count: MC=4, SATA=5-10, SelectN=5-8, Matrix=3-5 rows
â–¡ Each option â‰¤ 25 words
â–¡ Distractors are clinically plausible (not obviously wrong)
â–¡ No "All of the above" / "None of the above"
â–¡ Correct answer is defensible with evidence-based practice
â–¡ Options are mutually exclusive where required
```

### Dimension 4: Scoring Model Accuracy (Key 4)
```
â–¡ multipleChoice/trend/priorityAction/graphic/audioVideo/chartExhibit â†’ dichotomous, maxPoints: 1
â–¡ highlight/selectAll â†’ polytomous, +/- 1.0 penalty
â–¡ selectN â†’ polytomous, 0/1 no penalty
â–¡ matrixMatch â†’ polytomous, 0/1 per row
â–¡ clozeDropdown/dragAndDropCloze â†’ polytomous, 0/1 per blank
â–¡ bowtie â†’ linkage scoring
â–¡ orderedResponse â†’ dichotomous
â–¡ maxPoints calculated correctly based on item structure
```

### Dimension 5: Rationale Depth â€” ZERO GENERIC TOLERANCE (Key 5)
```
FAIL CONDITIONS (automatic):
  âœ— "This is correct because it is the right answer"
  âœ— "Option X is not the priority"
  âœ— "This is incorrect" (without WHY)
  âœ— "Monitor the patient" (without WHAT to monitor and WHY)
  âœ— Any rationale < 80 characters

PASS CONDITIONS (required):
  âœ“ Correct rationale explains pathophysiology or legal/safety basis
  âœ“ Each incorrect option gets a SPECIFIC explanation in THIS clinical context
  âœ“ Mentions the mechanism of action, not just the outcome
  âœ“ References specific lab values, vital signs, or assessment findings
```

### Dimension 6: Study Companion Completeness (Key 6)
```
â–¡ clinicalPearls: Array â‰¥ 1 entry. Each must be:
  - Specific to THIS clinical scenario (not generic textbook advice)
  - Actionable: tells the nurse WHAT to do or WHAT to monitor
  - â‰¥ 30 characters each
â–¡ questionTrap: {trap, howToOvercome} both present and specific
  - trap: Names the exact cognitive error (â‰¥ 20 chars)
  - howToOvercome: Concrete strategy with clinical reasoning (â‰¥ 30 chars)
â–¡ mnemonic: {title, expansion} present
  - Must be a real, recognized mnemonic relevant to the topic
  - Expansion must be accurate
â–¡ answerBreakdown: Array matching option count
  - Each entry: {label, content, isCorrect}
  - label: Option identifier
  - content: Specific explanation (â‰¥ 30 chars)
  - isCorrect: boolean
â–¡ reviewUnits: Array â‰¥ 1 entry
  - {heading, body, source} all present
  - body â‰¥ 50 characters of educational content
```

### Dimension 7: SBAR & Nurses' Notes Specificity (Key 7)
```
â–¡ SBAR format: Situation, Background, Assessment, Recommendation all present
â–¡ Word count: 120â€“160 words total
â–¡ Military time (HH:mm format) in all timestamps
â–¡ Terminology EXACTLY matches the item stem
  (e.g., if stem says "adult child" â†’ notes say "adult child", NOT "daughter")
â–¡ Notes must reflect SPECIFIC clinical findings, NOT generic templates
  âœ— "Patient evaluated for acute status changes" = FAIL (generic)
  âœ“ "Patient evaluated for acute respiratory distress. SpO2 dropped from 96% to 88% over 2 hours" = PASS
â–¡ Background must include relevant PMH, medications, and reason for admission
â–¡ Assessment must include specific objective findings (vitals, labs, physical exam)
â–¡ Recommendation must include specific interventions (not "Monitor vitals")
```

### Dimension 8: EHR Clinical Data Synchronization (Key 8)
```
RULE: Any clinical value referenced in the stem, options, or rationale MUST appear 
in the corresponding EHR tab. Orphaned references = CRITICAL failure.

â–¡ If stem mentions a lab value â†’ Lab tab must contain it with correct value
â–¡ If stem mentions a medication â†’ MAR tab must contain it with dose/route/frequency
â–¡ If stem mentions vital signs â†’ Vitals tab must have matching values
â–¡ If stem mentions imaging â†’ Radiology tab must have impression
â–¡ If stem mentions a physical finding â†’ Physical Exam tab must reflect it
â–¡ If question involves intervention â†’ Orders tab must have corresponding order
â–¡ Vitals must have â‰¥ 3 time-points for acute scenarios (trending)
â–¡ All EHR subsections that are relevant to the question MUST be populated
  âœ— Empty Labs tab when the question is about potassium levels = CRITICAL FAIL
```

### Dimension 9: Pedagogy & Taxonomy (Key 9)
```
â–¡ bloomLevel âˆˆ {remember, understand, apply, analyze, evaluate, create}
  - Must match the cognitive demand of the question
  - "Which is the FIRST action?" = analyze or evaluate, NOT remember
â–¡ cjmmStep alignment:
  - recognizeCues = identifying abnormal findings
  - analyzeCues = explaining WHY findings are abnormal
  - prioritizeHypotheses = ranking most likely/urgent conditions
  - generateSolutions = identifying appropriate interventions
  - takeAction = selecting the BEST/FIRST action
  - evaluateOutcomes = determining if interventions worked
â–¡ nclexCategory âˆˆ 8 valid NCLEX categories
â–¡ difficulty 1-5 calibrated to clinical complexity
â–¡ topicTags: at least 1, relevant to the clinical scenario
```

### Dimension 10: Item-Type-Specific Logic (Key 10)
```
highlight: â‰¥6 spans, â‰¥2 distractors, correctSpanIndices valid, passage exists
multipleChoice: exactly 4 options, correctOptionId matches one option
selectAll: 5-10 options, correctOptionIds â‰¥ 2 entries
orderedResponse: correctOrder matches all option IDs, used exactly once
matrixMatch: 3-5 rows, columns array, correctMatches covers all rows
clozeDropdown: 1-3 blanks, each with options and correctOption
dragAndDropCloze: template with blanks, options, correctOption per blank
bowtie: actions(â‰¥4), conditions(â‰¥3), parameters(â‰¥4), correct selections
trend: dataPoints â‰¥3 entries OR itemContext.tabs fallback, options array
priorityAction: exactly 4 options, correctOptionId, "first action" focus
hotspot: imageUrl, hotspots with coordinates
graphic: imageUrl or graphical context
audioVideo: mediaUrl, standard MC structure
chartExhibit: exhibits/itemContext.tabs with â‰¥2 data sources
```

### Dimension 11: Clinical Accuracy (Key 11)
```
â–¡ Drug dosages within safe therapeutic ranges
â–¡ Lab reference ranges correct per standard US adult values
â–¡ Pathophysiology descriptions medically accurate
â–¡ Nursing interventions within RN scope of practice
â–¡ Vital signs physiologically consistent with diagnosis
â–¡ Correct answer truly the BEST answer per evidence-based practice
â–¡ No outdated or debunked clinical practices
```

### Dimension 12: Isolation & Allergy Cross-Reference (Key 12) â€” NEW
```
ISOLATION LOGIC:
  If stem/diagnosis involves:
  âœ“ TB, Measles, Varicella, Disseminated Zoster â†’ iso: "Airborne"
  âœ“ MRSA, C. diff, VRE, Scabies, RSV â†’ iso: "Contact"
  âœ“ Influenza, Meningococcal, Pertussis, Mumps â†’ iso: "Droplet"
  âœ“ Chicken Pox â†’ iso: "Airborne + Contact"
  âœ“ No infectious component â†’ iso: "Standard"
  
  The patient.iso field in the CaseStudy wrapper MUST match.
  If the item has an infectious disease topic but iso is "Standard" â†’ FAIL

ALLERGY LOGIC:
  If MAR medications are present, cross-reference with patient.allergies:
  âœ“ Penicillin allergy + Amoxicillin in MAR â†’ CRITICAL FAIL (contraindicated)
  âœ“ Sulfa allergy + Sulfamethoxazole â†’ CRITICAL FAIL
  âœ“ NSAID allergy + Ibuprofen/Ketorolac â†’ CRITICAL FAIL
  âœ“ Latex allergy should be noted when relevant
  
  Allergy cross-families to check:
  - Penicillin: amoxicillin, ampicillin, piperacillin, nafcillin
  - Sulfa: sulfamethoxazole, sulfasalazine, furosemide (weak), thiazides
  - Cephalosporin: cephalexin, ceftriaxone, cefazolin (cross with penicillin ~1-2%)
  - NSAID: ibuprofen, naproxen, ketorolac, aspirin
  
  If allergies array is empty or ["None"] when medications are involved:
  â†’ Flag as WARNING (realistic patients often have allergies)
  â†’ HEALER should add a clinically appropriate allergy that does NOT conflict with ordered meds
```

---

## ğŸ”§ The REFILLER Role (Key 13) â€” Comprehensive Data Enrichment

The REFILLER's job is to transform ALL generic/placeholder content into clinically specific data.

### What Gets Refilled:

| Generic Content (FAIL) | Specific Replacement (PASS) |
|:---|:---|
| "Hx of priority clinical concerns relevant to current admission" | "Hx of Type 2 DM Ã— 15 years, HTN, and Stage 3 CKD. Admitted for acute exacerbation of heart failure" |
| "Initial assessment confirms findings described in question stem" | "Initial assessment reveals bibasilar crackles, JVD, 3+ pitting edema bilateral LE, SpO2 88% on RA" |
| "Monitor vitals and response to interventions" | "Recommend continuous telemetry, strict I&O, daily weights, BMP q6h, furosemide 40mg IV now" |
| "Patient evaluated for acute status changes" | "Patient evaluated for acute hypoxia secondary to pulmonary edema. ABG shows pH 7.31, PaCO2 48, PaO2 62" |
| Empty Labs tab when question involves potassium | Add: K+ 5.8 mEq/L (H), Na 138, BUN 42 (H), Cr 2.1 (H) |
| Empty MAR when question involves medication safety | Add: Full medication list with dose, route, frequency, last admin time |
| Empty Radiology when question involves chest findings | Add: "CXR: Bilateral pleural effusions, cardiomegaly, pulmonary vascular congestion" |
| Empty Physical Exam when question involves assessment | Add: System-specific findings matching the clinical scenario |
| iso: "Standard" when patient has TB | Change to: iso: "Airborne" |
| allergies: [] when medications are ordered | Add: Clinically appropriate allergy (e.g., "Codeine" if no opioids ordered) |

### REFILLER AI Prompt Template:
```
You are a 20-year NCLEX Psychometrician and Clinical Content Specialist.

This item has GENERIC or MISSING clinical data. Your mission is to REPLACE all generic 
content with clinically SPECIFIC, patient-appropriate data.

RULES:
1. Every SBAR field must contain specific clinical details (vitals, labs, timing, findings)
2. If the question mentions labs/meds/vitals, the EHR tabs MUST contain matching data
3. Background must include specific PMH with durations ("Type 2 DM Ã— 15 years")
4. Assessment must include objective findings with numerical values
5. Recommendation must include specific medications with doses and monitoring parameters
6. Isolation type must match the infectious disease (if any)
7. Allergies must be realistic and NOT conflict with ordered medications
8. All nurses' notes must read like a real clinical chart, NOT a template
9. Physical exam findings must be objective ("3+ pitting edema") not subjective ("swollen")

CURRENT ITEM: {{ITEM_JSON}}

Return the COMPLETE item with ALL generic content replaced by specific clinical data.
Return ONLY pure JSON.
```

---

## ğŸš€ Execution Workflow

### One-Button Trigger (Vercel UI)

The **SentinelQA** page in the Item Bank has a `[ğŸ›¡ï¸ Run SENTINEL]` button that triggers:

```
PHASE 1: STRUCTURAL SCAN (Instant â€” No AI)
â”œâ”€â”€ Check all 14 type-specific schemas
â”œâ”€â”€ Validate scoring models
â”œâ”€â”€ Flag missing required fields
â”œâ”€â”€ Flag generic SBAR content patterns
â”œâ”€â”€ Cross-reference isolation/allergy vs. stem topics
â””â”€â”€ Output: Structural Report

PHASE 2: DEEP AI AUDIT (14 Keys in rotation, 4s pacing)
â”œâ”€â”€ For each item:
â”‚   â”œâ”€â”€ Key 2: Stem quality check â†’ improve if unclear
â”‚   â”œâ”€â”€ Key 3: Option logic check
â”‚   â”œâ”€â”€ Key 5: Rationale depth (anti-filler enforcement)
â”‚   â”œâ”€â”€ Key 6: Study Companion completeness
â”‚   â”œâ”€â”€ Key 7: SBAR specificity check
â”‚   â”œâ”€â”€ Key 8: EHR synchronization audit
â”‚   â”œâ”€â”€ Key 9: Pedagogy/taxonomy validation
â”‚   â”œâ”€â”€ Key 11: Clinical accuracy review
â”‚   â””â”€â”€ Key 12: Isolation & allergy cross-reference
â””â”€â”€ Output: Per-item AI Audit Results

PHASE 3: AUTO-HEAL & REFILL
â”œâ”€â”€ Items with severity â‰¥ MEDIUM â†’ sent to REFILLER (Key 13) + HEALER (Key 14)
â”œâ”€â”€ REFILLER: Replaces generic â†’ specific clinical data
â”œâ”€â”€ HEALER: Fixes structural/scoring/option defects
â”œâ”€â”€ Re-validate healed items through Phase 1
â”‚   â””â”€â”€ If still failing â†’ QUARANTINE (do not push)
â””â”€â”€ Output: Healed Items + Change Log

PHASE 4: PUSH & REPORT
â”œâ”€â”€ Upsert healed items to Supabase
â”œâ”€â”€ Add sentinelStatus: "sentinel_v2_{timestamp}" to each processed item
â”œâ”€â”€ Generate SENTINEL Report:
â”‚   â”œâ”€â”€ Global health score
â”‚   â”œâ”€â”€ Per-dimension pass rates
â”‚   â”œâ”€â”€ Per-type distribution
â”‚   â”œâ”€â”€ Per-item diagnostics (expandable)
â”‚   â”œâ”€â”€ Top recommendations
â”‚   â””â”€â”€ Quarantined items list
â””â”€â”€ Display report in the SentinelQA dashboard
```

---

## ğŸ“Š SENTINEL Report & Recommendations

The report displayed in the Vercel UI includes:

### 1. Global Health Score (0-100)
A single ring chart showing overall vault quality.

### 2. Dimension Heatmap
8 dimension cards with pass/warn/fail counts and clickable filters.

### 3. Per-Item Table
Sortable, filterable table with:
- Status badge (PASS/WARN/FAIL)
- Item ID
- Item Type
- QA Score
- Issue count by severity
- Expandable detail panel

### 4. Recommendations Section
```
ğŸ”´ CRITICAL: [count] items have clinically inaccurate content â†’ must review manually
ğŸŸ  HIGH: [count] items had generic rationale â†’ auto-healed with pathophysiology
ğŸŸ¡ MEDIUM: [count] items missing Study Companion data â†’ auto-filled
ğŸŸ¢ LOW: [count] items had minor style issues â†’ auto-corrected
ğŸ“‹ NEXT STEPS: 
  1. Review quarantined items manually
  2. Run SENTINEL again after manual fixes
  3. Focus item generation on under-represented types: [list]
```

---

## ğŸ›¡ï¸ Severity Classification

| Severity | Description | Action |
|:---|:---|:---|
| ğŸ”´ **CRITICAL** | Clinically inaccurate, wrong correct answer, medication-allergy conflict, wrong scoring | **QUARANTINE** |
| ğŸŸ  **HIGH** | Generic rationale, missing answerBreakdown, empty SBAR fields, EHR desync | **AUTO-HEAL** |
| ğŸŸ¡ **MEDIUM** | Missing pearls/trap/mnemonic, stem > 50 words, option count off, isolation mismatch | **AUTO-HEAL** |
| ğŸŸ¢ **LOW** | Suboptimal wording, minor style issues, weak distractor | **LOG** |

---

## âš™ï¸ Key Rotation & Rate Limiting

```javascript
const KEY_ROLES = {
    1:  'STRUCT-VALIDATOR',     // No AI needed
    2:  'STEM-SURGEON',
    3:  'OPTION-ARCHITECT',
    4:  'SCORE-AUDITOR',        // No AI needed
    5:  'RATIONALE-PATHOLOGIST',
    6:  'PEARL-TRAP-MNEMONIC',
    7:  'SBAR-COMPLIANCE',
    8:  'EHR-SYNC',
    9:  'PEDAGOGY-MAPPER',
    10: 'ITEM-TYPE-LOGIC',      // Mostly deterministic
    11: 'CLINICAL-ACCURACY',
    12: 'ISOLATION-ALLERGY',
    13: 'REFILLER',
    14: 'HEALER'
};

// Pacing: 4 seconds between API calls
// Parallelism: 2 concurrent calls max (different keys)
// Temperature: 0.1 for audit (strict), 0.7 for healing (creative fixes)
// responseMimeType: "application/json" (always)
// Retry: 3 attempts, exponential backoff (4s â†’ 8s â†’ 16s)
// Cooldown: 60s after 429 errors
```

---

## ğŸ† World-Class Quality Targets

| Metric | Target | Description |
|:---|:---:|:---|
| Structural Pass Rate | â‰¥ 99% | All items have required JSON fields |
| Rationale Depth | â‰¥ 90% A-grade | No generic filler in any rationale |
| Study Companion Readiness | 100% | Every item has Pearls + Trap + Mnemonic + Breakdown |
| Answer Breakdown Coverage | 100% | Every option has a labeled breakdown entry |
| Scoring Model Accuracy | 100% | Scoring method matches item type |
| EHR Synchronization | â‰¥ 95% | Stem references match EHR tab data |
| Clinical Accuracy | 100% | Zero medically inaccurate items |
| SBAR Specificity | â‰¥ 95% | No generic nurses' notes |
| Isolation Compliance | 100% | Isolation type matches diagnosis |
| Allergy Safety | 100% | No medication-allergy conflicts |

---

## ğŸ“ File Structure

```
Senior NCLEX/
â”œâ”€â”€ sentinel_qa_rotator.cjs          â† Main execution script
â”œâ”€â”€ QA_ROTATOR_SERVICE.md            â† This specification
â”œâ”€â”€ validation/
â”‚   â””â”€â”€ itemBankQA.ts                â† Deterministic QA engine (Phase 1)
â”œâ”€â”€ components/navigation/
â”‚   â””â”€â”€ SentinelQAPage.tsx           â† Vercel UI dashboard
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sentinel-reports/            â† Historical audit reports
â”‚   â””â”€â”€ quarantine/                  â† Items too broken to auto-heal
â””â”€â”€ .env                             â† GEMINI_API_KEY_1 through _14
```

---

## ğŸ’¡ Expert-Level Design Principles (20+ Years Experience)

1. **Deterministic first, AI second** â€” Run structural checks instantly. Only call AI for semantic analysis. This saves 40% of API calls.

2. **Never trust AI blindly** â€” After the HEALER fixes an item, re-run it through Phase 1 structural validation. If it still fails â†’ quarantine, never push.

3. **Context is everything** â€” The REFILLER doesn't just "add data." It reads the item stem, understands the clinical scenario, and generates data that would logically appear in a real patient chart for that specific diagnosis.

4. **Isolation is not optional** â€” A student practicing for NCLEX who sees "Standard" isolation on a TB patient will develop wrong clinical habits. Every infectious disease question MUST have the correct isolation type.

5. **Allergies tell a story** â€” An empty allergy list is unrealistic. Real patients have allergies. Adding a non-conflicting allergy (like "Codeine" when no opioids are ordered) adds realism without creating a drug interaction trap question.

6. **The Study Companion is not a sidebar feature â€” it's a learning engine** â€” If clinical pearls say "Monitor vitals," the student learns nothing. If they say "In DKA, potassium shifts intracellularly as pH normalizes â€” monitor K+ q2h even if initially hyperkalemic," the student gains a clinical edge.

7. **Log everything** â€” Every API call, every verdict, every heal operation. This forensic trail validates your item bank for accreditation reviews.

8. **Quarantine > Bad Data** â€” An empty slot in the vault is infinitely better than a wrong item. Never push a broken item to production.

---

*SENTINEL v2.0 â€” Built for the 2026 NCLEX-RN NGN Standard*
*"No item graduates without a 12-dimension audit."*
*This system replaces ALL previous QA systems.*
